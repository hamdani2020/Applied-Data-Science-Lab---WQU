# Applied Data Science Lab - WQU

## Content
- [HOUSING IN MEXICO](## HOUSING IN MEXICO)

![image](/wqu.png)

I have completed eight end-to-end, applied data science projects. In each project, I accessed data from files, SQL and NoSQL databases and APIs. I have demonstrated my ability to explore and clean data, create functions and ETL pipelines to prepare training sets. I have built machine learning models for supervised and unsupervised learning tasks, and have created visualizations to explain data characteristics and model predictions for non-technical audiences.

## PROJECTS
![image](/wqu1.png)

## HOUSING IN MEXICO
I used a dataset of 21,000 properties to determine if real estate prices are influence more by property size or location.
- I imported and cleaned data form a CSV file
- I built data visualizations and
- Examine the relationship between two variables using correlation.

## APARTMENT SALES IN BUENOS AITES
I build a linear regression model to predict apartment prices in Argentina.
- I created a data pipeline to impute missing values and encode categorical features.
- I improve model preformance by reducing overfitting.

## AIR QUALITY IN NAIROBI
I built an ARMA time-series model to predict particulate matter levels in kenya.
- Extracted data form MongoDB database using pymongo and
- Improved model performance through hyperparameter tunning.
- Applied rolling average, autocorrelation and lag operations to time-series data variables.

## EARTHQUAKE DAMAGE IN NEPAL
- Built logistic regression and decision tree models to predict earthquake damage to buildings.
- Extracted data from a SQLite database, and
- Revealed the biases in data that can lead to discrimination.

## BANKRUPTCY IN POLAND
- Built random forest and gradient boosting models to predict whether a company will go bankrupt.
- Navigated the Linux command line.
- Addressed imbalanced data through resampling.
- considered the impact of performance metrics precision and recall.

## CUSTOMER SEGMENTATION IN THE US
- Built a k-means model to cluster US consumers into groups.
- Used principal component analysis(PCA) for data visualization.
- Created an interactive dashboard with Plotly Dash.

## A/B TESTING AT WORLDQUANT UNIVERSITY
- Conducted a chi-square test to determine if sending an email can increase program enrollment at WQU.
- Built custom Python classes to implement an ETL process.
- Created an interactive data application following a three-tiered design pattern.

## VOLATILITY FORECASTING IN INDIA
- Created a GARCH time series model to predict asset volatility.
- Acquired stock data through an API, cleaned and stored it in a SQLite database.
- Built my own API to serve model predictions.

### Scan and verify badge from credly
![image](/qrcode.png)
